# -*- coding: utf-8 -*-
"""LSTM_Price_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wT8It4OBeORxx9vUekaxwCF1qgvAKtVL

#Data Loading
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('Aus_grocery_synthetic_dataset2.csv')
df.head()

"""##Removing all rows whose "unit_price_x value is either "0" or "NaN"."""

df = df[(df['unit_price_x'] != 0) & (df['unit_price_x'].notna())]

"""#Transfering date column type to "DateTimeObject"
"""

def parse_mixed_dates(date):
    try:
        # Attempt parsing as MM/DD/YYYY
        return pd.to_datetime(date, format='%m/%d/%Y')
    except ValueError:
        try:
            # Attempt parsing as DD/MM/YYYY
            return pd.to_datetime(date, format='%d/%m/%Y')
        except ValueError:
            return pd.NaT  # Return NaT if both fail

# Apply the function to parse mixed formats
df['RunDate_parsed'] = df['RunDate'].apply(parse_mixed_dates)

df.info()

print(df.describe())

# Plot for unit_price_x
sns.histplot(df['unit_price_x'], kde=True)
plt.title('Distribution of unit_price_x')
plt.show()

"""##Normaliz the "unit_price_x" column"""

from sklearn.preprocessing import MinMaxScaler

# Initialize the scaler
scaler = MinMaxScaler()

# Fit and transform the unit_price_x column
df['unit_price_x_normalized'] = scaler.fit_transform(df[['unit_price_x']])

# Check the result
# Plot for unit_price_x
sns.histplot(df['unit_price_x_normalized'], kde=True)
plt.title('Distribution of unit_price_x_normalized')
plt.show()

"""##LSTM Model for price prediction"""

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.optimizers import Adam

price_data = df['unit_price_x_normalized'].values

# Split data into training and testing
train_size = int(len(price_data) * 0.8)
train, test = price_data[:train_size], price_data[train_size:]

# Create the dataset matrix
def create_dataset(data, look_back=1):
    X, Y = [], []
    for i in range(len(data)-look_back-1):
        a = data[i:(i+look_back)]
        X.append(a)
        Y.append(data[i + look_back])
    return np.array(X), np.array(Y)

look_back = 1
X_train, y_train = create_dataset(train, look_back)
X_test, y_test = create_dataset(test, look_back)

X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

# Build the LSTM model
model = Sequential()
model.add(LSTM(50, input_shape=(look_back, 1)))
model.add(Dense(1))
model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error')

# Early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Train the model
history = model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=2, validation_data=(X_test, y_test), callbacks=[early_stopping])

# Make predictions
train_predict = model.predict(X_train)
test_predict = model.predict(X_test)

# Inverse transform predictions
train_predict = scaler.inverse_transform(train_predict)
y_train = scaler.inverse_transform([y_train])
test_predict = scaler.inverse_transform(test_predict)
y_test = scaler.inverse_transform([y_test])

# Calculate performance metrics
mae = mean_absolute_error(y_test[0], test_predict[:,0])
mse = mean_squared_error(y_test[0], test_predict[:,0])
rmse = np.sqrt(mse)
r2 = r2_score(y_test[0], test_predict[:,0])

print(f"Mean Absolute Error (MAE): {mae}")
print(f"Mean Squared Error (MSE): {mse}")
print(f"Root Mean Squared Error (RMSE): {rmse}")
print(f"R-Squared: {r2}")

# Plot the results
plt.figure(figsize=(10,5))
plt.plot(y_test[0], label='Testing Data')
plt.plot(test_predict[:,0], label='LSTM Forecast')
plt.legend(loc='best')
plt.title('LSTM Model Forecast on Normalized Data')
plt.show()

import pickle
with open('LSTM_model_MinMax_normalization.pkl', 'wb') as pkl:
  pickle.dump(model, pkl)

